{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the interactive component of the [ETICS 2022 summer school](https://www.gdr-mascotnum.fr/etics.html) session on \"Modern Kernel Methods in Machine Learning\" by [Danica Sutherland](https://djsutherland.ml).\n",
    "Slides are available [here](https://djsutherland.ml/slides/etics-22/) (or in [pdf](https://djsutherland.ml/slides/etics-22.pdf)).\n",
    "\n",
    "Previous versions of these materials:\n",
    "\n",
    "- [For DS3 2021](https://github.com/djsutherland/ds3-kernels-21/)\n",
    "- For [DS3 2019](https://github.com/djsutherland/ds3-kernels/), in discussion with [Bharath Sriperumbudur](http://personal.psu.edu/bks18/)\n",
    "- Testing material partially based on [a DS3 2018 version](https://github.com/karlnapf/ds3_kernel_testing) by [Heiko Strathmann](http://herrstrathmann.de/) in discussion with [Arthur Gretton](http://www.gatsby.ucl.ac.uk/~gretton/).\n",
    "\n",
    "We'll cover, in varying levels of detail, the following topics:\n",
    "\n",
    "- Solving regression problems with kernel ridge regression ([`ridge.ipynb`](ridge.ipynb)):\n",
    "  - The \"standard\" approach.\n",
    "  - Kernel choice, and how it affects the resulting fit.\n",
    "  - Optionally: learning an appropriate kernel function in a meta-learning setting.\n",
    "- Two-sample testing with the kernel Maximum Mean Discrepancy (MMD) ([`testing.ipynb`](testing.ipynb)):\n",
    "  - Estimators for the MMD.\n",
    "  - Learning an appropriate kernel function.\n",
    "\n",
    "## Colab\n",
    "\n",
    "These notebooks are available on Google Colab: [ridge](https://colab.research.google.com/github/djsutherland/etics-kernels-22/blob/built/ridge.ipynb) or [testing](https://colab.research.google.com/github/djsutherland/etics-kernels-22/blob/built/testing.ipynb). You don't have to set anything up yourself and it runs on cloud resources, so this is probably the easiest option. If you want to use the GPU, click Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n",
    "\n",
    "## Local setup\n",
    "\n",
    "Otherwise, you can install stuff locally.\n",
    "\n",
    "Run `check_imports_and_download.py` to see if everything you need is installed (and download some more small datasets if necessary). If that works, you're set; otherwise, read on.\n",
    "\n",
    "\n",
    "### Files\n",
    "There are a few Python files and some data files in the repository. By far the easiest thing to do is just put them all in the same directory:\n",
    "\n",
    "```\n",
    "git clone --single-branch https://github.com/djsutherland/etics-kernels-22\n",
    "```\n",
    "\n",
    "#### Python version\n",
    "This notebook requires Python 3.6+.\n",
    "\n",
    "If you've somehow still only used Python 2, it's time to [stop living in the past](https://python3statement.org/), but don't worry! It's almost the same; for the purposes of this notebook, you probably only need to know that you should write `print(\"hi\")` since it's a function call now, and you can write `A @ B` instead of `np.dot(A, B)`.\n",
    "\n",
    "#### Python packages\n",
    "\n",
    "The main thing we use is PyTorch and Jupyter. If you already have those set up, you should be fine; just additionally make sure you also have (with `conda install` or `pip install`) `seaborn`, `tqdm`, and `sckit-learn`. We import everything right at the start, so if that runs you shouldn't hit any surprises later on.\n",
    "\n",
    "If you don't already have a setup you're happy with, we recommend the `conda` package manager - start by installing [miniconda](https://docs.conda.io/en/latest/miniconda.html). Then you can create an environment with everything you need as:\n",
    "\n",
    "```bash\n",
    "# replace cpuonly with an appropriate cudatoolkit version if you want GPU support\n",
    "conda create --name etics-kernels --override-channels -c pytorch -c defaults --strict-channel-priority python=3 notebook ipywidgets numpy scipy scikit-learn matplotlib seaborn tqdm pytorch torchvision cpuonly\n",
    "\n",
    "conda activate etics-kernels\n",
    "\n",
    "git clone https://github.com/djsutherland/etics-kernels-22\n",
    "cd etics-kernels-22\n",
    "python check_imports_and_download.py\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "(If you have an old conda setup, you can use `source activate` instead of `conda activate`, but it's better to [switch to the new style of activation](https://conda.io/projects/conda/en/latest/release-notes.html#recommended-change-to-enable-conda-in-your-shell). This won't matter for this tutorial, but it's general good practice.)\n",
    "\n",
    "(You can make your life easier when using jupyter notebooks with multiple kernels by installing `nb_conda_kernels`, but as long as you install and run `jupyter` from inside the env it will also be fine.)\n",
    "\n",
    "\n",
    "## PyTorch\n",
    "\n",
    "We're going to use PyTorch in this tutorial, even though we're not doing a ton of \"deep learning.\" (The CPU version will be fine, though a GPU might let you get slightly better performance in some of the \"advanced\" sections.)\n",
    "\n",
    "If you haven't used PyTorch before, don't worry! The API is unfortunately a little different from NumPy (and TensorFlow), but it's pretty easy to get used to; you can refer to [a cheat sheet vs NumPy](https://github.com/wkentaro/pytorch-for-numpy-users/blob/master/README.md) as well as the docs: [tensor methods](https://pytorch.org/docs/stable/tensors.html) and [the `torch` namespace](https://pytorch.org/docs/stable/torch.html#torch.eq). Feel free to ask if you have trouble figuring something out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\DeclareMathOperator*{\\argmin}{argmin}\n",
    "\\DeclareMathOperator*{\\E}{\\mathbb E}\n",
    "\\newcommand{\\R}{\\mathbb R}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:01.261949Z",
     "iopub.status.busy": "2022-10-02T19:25:01.261518Z",
     "iopub.status.idle": "2022-10-02T19:25:03.268105Z",
     "shell.execute_reply": "2022-10-02T19:25:03.268333Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    import google.colab\n",
    "except ImportError:\n",
    "    pass\n",
    "else:\n",
    "    if not os.path.exists('data/blobs.npz'):\n",
    "        !git clone https://github.com/djsutherland/etics-kernels-22\n",
    "        os.chdir('etics-kernels-22')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(context='notebook')\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "# from tqdm import tqdm  # if you're in JupyterLab/etc and the above doesn't work well\n",
    "\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "import support\n",
    "from support import as_tensors, plot_confusion_matrix, LazyKernel, pil_grid\n",
    "\n",
    "# Download some datasets. We won't need these until later; go ahead and read ahead\n",
    "# while they're downloading if you want....\n",
    "torchvision.datasets.MNIST(root='data', download=True)\n",
    "support.CombinedOmniglot(root='data', download=True)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:03.271024Z",
     "iopub.status.busy": "2022-10-02T19:25:03.270657Z",
     "iopub.status.idle": "2022-10-02T19:25:04.530917Z",
     "shell.execute_reply": "2022-10-02T19:25:04.529700Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is just checking that tqdm works okay.\n",
    "# If it doesn't work, then switch to the \"from tqdm import tqdm\" line above.\n",
    "import time\n",
    "print(\"\")\n",
    "for _ in tqdm(range(100)):\n",
    "    time.sleep(.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note\n",
    "\n",
    "Please ask me for help if you get stuck! Whether it's with a PyTorch thing, some other code thing, or especially something conceptual \u2013\u00a0that's what I'm here for. Solutions are also available in [`solutions-ridge.ipynb`](solutions-ridge.ipynb), but you're better off not rushing straight to those; I'm happy to help you try to help you work things out yourself, which is probably better for you. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression\n",
    "Okay, time to get going.\n",
    "\n",
    "We're going to start with implementing kernel ridge regression. First, here's a toy dataset to test your code on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.552797Z",
     "iopub.status.busy": "2022-10-02T19:25:04.552413Z",
     "iopub.status.idle": "2022-10-02T19:25:04.644373Z",
     "shell.execute_reply": "2022-10-02T19:25:04.644699Z"
    }
   },
   "outputs": [],
   "source": [
    "with np.load('data/ridge-toy.npz') as f:\n",
    "    toy_X = f['X']\n",
    "    toy_y = f['y']\n",
    "toy_X_train, toy_X_test, toy_y_train, toy_y_test = model_selection.train_test_split(\n",
    "    toy_X, toy_y, train_size=200)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(toy_X_train[:, 0], toy_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data looks like it could be well-modeled by a Gaussian RBF kernel. We'll need a fairly small bandwidth. See the local minimum a little above 0.15 and the local maximum a little past 0.2? The Gaussian kernel still has a fair amount of influnce one bandwidth away, so we want to make the bandwidth a little smaller than that; say 0.05. So, first let's implement the kernel.\n",
    "\n",
    "<sup>I totally eyeballed that like I said, and definitely didn't just generate the true function in the first place from an RBF function with that bandwidth....</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, first, let's implement some kernels first. I've put some helper infrastructure in the `LazyKernel` class (in [`support.kernels`](support/kernels.py)) that will be especially useful later; for now, it's just a way to organize computing it. Here's an example of how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.647322Z",
     "iopub.status.busy": "2022-10-02T19:25:04.646907Z",
     "iopub.status.idle": "2022-10-02T19:25:04.648384Z",
     "shell.execute_reply": "2022-10-02T19:25:04.648691Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearKernel(LazyKernel):\n",
    "    def _compute(self, A, B):\n",
    "        return A @ B.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_compute` method computes the kernel between two inputs `A` and `B`. (`.t()` is PyTorch for taking a transpose; `@` is the nifty Python 3.6+ syntax for matrix multiplication.) The inputs here are *batches* of data points, for efficient computation: `A` is shape `n_A x dim`, `B` is shape `n_B x dim`. Each row is a data point, of the same dimension, but we might have a different number of data points in `A` and `B`. The result is shape `n_A x n_B`.\n",
    "\n",
    "The `LazyKernel` base class lets us use this in various ways. First, to find the kernel from one set of points to another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.651465Z",
     "iopub.status.busy": "2022-10-02T19:25:04.651051Z",
     "iopub.status.idle": "2022-10-02T19:25:04.669331Z",
     "shell.execute_reply": "2022-10-02T19:25:04.669602Z"
    }
   },
   "outputs": [],
   "source": [
    "K = LinearKernel(toy_X_train, toy_X_test)\n",
    "print(K)\n",
    "K.XY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the X-to-X (`XX`) and Y-to-Y (`YY`) kernel matrices from the same object (which are the result of `_compute(X, X)` and `_compute(Y, Y)`). These aren't computed until you need them, but then they're cached after you use them the first time; this is why it's a `LazyKernel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.671926Z",
     "iopub.status.busy": "2022-10-02T19:25:04.671525Z",
     "iopub.status.idle": "2022-10-02T19:25:04.674368Z",
     "shell.execute_reply": "2022-10-02T19:25:04.674569Z"
    }
   },
   "outputs": [],
   "source": [
    "K.XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only want the kernel matrix for a dataset to itself, you can just not pass the second argument. Then K.XY won't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.676887Z",
     "iopub.status.busy": "2022-10-02T19:25:04.676508Z",
     "iopub.status.idle": "2022-10-02T19:25:04.679391Z",
     "shell.execute_reply": "2022-10-02T19:25:04.679642Z"
    }
   },
   "outputs": [],
   "source": [
    "LinearKernel(toy_X_train).XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass three arguments; then there'll be `XZ`, etc. You can also access them with e.g. `K[0, 2]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of a slightly more complex kernel class, with some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.683052Z",
     "iopub.status.busy": "2022-10-02T19:25:04.682723Z",
     "iopub.status.idle": "2022-10-02T19:25:04.683921Z",
     "shell.execute_reply": "2022-10-02T19:25:04.684178Z"
    }
   },
   "outputs": [],
   "source": [
    "class PolynomialKernel(LazyKernel):\n",
    "    def __init__(self, X, *rest, degree=3, gamma=None, coef0=1):\n",
    "        super().__init__(X, *rest)\n",
    "        self.degree = degree\n",
    "        self.gamma = 1 / X.shape[1] if gamma is None else gamma\n",
    "        self.coef0 = coef0\n",
    "\n",
    "    def _compute(self, A, B):\n",
    "        XY = A @ B.t()\n",
    "        return (self.gamma * XY + self.coef0) ** self.degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the Gaussian RBF kernel is\n",
    "$$k(X_i, X_j) = \\exp\\left( -\\frac{1}{2 \\sigma^2} \\lVert X_i - X_j \\rVert^2 \\right).$$\n",
    "\n",
    "**Exercise:** Implement that here.\n",
    "\n",
    "It might be helpful to recall that\n",
    "$$\\lVert X_i - X_j \\rVert^2 = \\lVert X_i \\rVert^2 + \\lVert X_j \\rVert^2 - 2 X_i^T X_j;$$\n",
    "you should probably convert that into a matrix form to implement it.\n",
    "\n",
    "Alternatively, [`torch.pdist`](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.pdist) computes these distances, but it only gives you the upper triangle of the matrix so you'll have to turn it into a full symmetric matrix yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.687222Z",
     "iopub.status.busy": "2022-10-02T19:25:04.685580Z",
     "iopub.status.idle": "2022-10-02T19:25:04.688433Z",
     "shell.execute_reply": "2022-10-02T19:25:04.688763Z"
    }
   },
   "outputs": [],
   "source": [
    "class RBFKernel(LazyKernel):\n",
    "    def __init__(self, *parts, sigma=1):\n",
    "        super().__init__(*parts)\n",
    "        self.sigma = sigma\n",
    "        # This next line doesn't really matter here, but helps a bit in the mmd stuff:\n",
    "        self.const_diagonal = 1  # Declares that k(x, x) = 1 for any x\n",
    "    \n",
    "    def _compute(self, A, B):  # TODO: implement _compute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your implementation against scikit-learn's implementation (but it doesn't work in PyTorch, so don't just use it directly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.692298Z",
     "iopub.status.busy": "2022-10-02T19:25:04.691932Z",
     "iopub.status.idle": "2022-10-02T19:25:04.704945Z",
     "shell.execute_reply": "2022-10-02T19:25:04.705175Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma = np.random.lognormal()\n",
    "K = RBFKernel(toy_X_train, toy_X_test, sigma=sigma)\n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "gamma = 1 / (2 * sigma**2)  # sklearn uses this parameterization\n",
    "assert np.allclose(K.XX.numpy(), rbf_kernel(toy_X_train, gamma=gamma))\n",
    "assert np.allclose(K.XY.numpy(), rbf_kernel(toy_X_train, toy_X_test, gamma=gamma))\n",
    "assert np.allclose(K.YY.numpy(), rbf_kernel(toy_X_test, gamma=gamma))\n",
    "print(\"Passed the assertions, seems good!\")\n",
    "\n",
    "del rbf_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing ridge regression\n",
    "\n",
    "Okay, now we can compute all kinds of kernels; let's actually use them for something. First, let's implement kernel ridge regression:\n",
    "$$\n",
    "  \\min_{f \\in \\mathcal{H}} \\frac{1}{n} \\sum_{i=1}^n \\lVert f(X_i) - y_i \\rVert^2 + \\lambda \\lVert f \\rVert_{\\mathcal{H}}^2 \n",
    ".$$\n",
    "As we saw in the lecture, the representer theorem tells us that $f(x) = \\sum_{i=1}^n \\alpha_i k(X_i, x)$.\n",
    "We *could* then solve this with gradient descent or some other iterative optimizer; indeed, sometimes this (usually with conjugate gradient) is the most effective option.\n",
    "But for today's purposes, we're going to prefer the analytical solution:\n",
    "some calculus gives us\n",
    "$$\\alpha = (K + n \\lambda I)^{-1} y, \\tag{*}$$\n",
    "where $K_{ij} = k(X_i, X_j)$.\n",
    "\n",
    "(If you're familiar with Gaussian processes but not ridge regression, the function $f$ is exactly the posterior mean of a Gaussian process. If you're not familiar with GPs, never mind.)\n",
    "\n",
    "There's also one more wrinkle: we're going to need to compute ridge regression for multiple outputs $y$ at once with the same $X$s. This just means solving the linear system for more than one $y$ at once; most software, including PyTorch, supports this built-in.\n",
    "\n",
    "To implement $\\textrm{(*)}$, there are (at least) two approaches.\n",
    "\n",
    "- [`torch.linalg.solve`](https://pytorch.org/docs/stable/torch.html#torch.solve) is a general-purpose matrix solver, which uses an [LU decomposition](https://en.wikipedia.org/wiki/LU_decomposition). This doesn't exploit the special structure of kernel matrices (namely that they're [positive-definite](https://en.wikipedia.org/wiki/Definiteness_of_a_matrix)).\n",
    "\n",
    "- You could also use a [Cholesky factorization](https://en.wikipedia.org/wiki/Cholesky_factorization), which is the standard approach for positive-definite matrices, and will be somewhat faster. You could implement this with [`torch.linalg.cholesky`](https://pytorch.org/docs/stable/torch.html#torch.cholesky) and then either [`torch.cholesky_solve`](https://pytorch.org/docs/stable/torch.html#torch.cholesky_solve) or [`torch.triangular_solve`](https://pytorch.org/docs/stable/torch.html#torch.triangular_solve) directly; Cholesky gives us $L$ such that $K + n \\lambda I = L L^T$, so you'll want $\\alpha = (L L^T)^{-1} y = L^{-T} (L^{-1} y)$. (Make sure to pass `upper=False` to `triangular_solve`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.707035Z",
     "iopub.status.busy": "2022-10-02T19:25:04.706601Z",
     "iopub.status.idle": "2022-10-02T19:25:04.713080Z",
     "shell.execute_reply": "2022-10-02T19:25:04.713268Z"
    }
   },
   "outputs": [],
   "source": [
    "class KernelRidgeRegression:\n",
    "    def __init__(\n",
    "        self,\n",
    "        reg_wt=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        reg_wt: The regularization weight lambda.\n",
    "        \"\"\"\n",
    "        self.reg_wt = reg_wt\n",
    "    \n",
    "    def fit(self, K_XX, y):\n",
    "        \"\"\"\n",
    "        Fit the ridge regression:\n",
    "        \n",
    "          K_XX: The training kernel matrix, of shape [n_train, n_train].\n",
    "          y: The training labels, of shape [n_train] or [n_train, n_labels].        \n",
    "        \"\"\"\n",
    "        K_XX, y = as_tensors(K_XX, y)\n",
    "        \n",
    "        assert len(K_XX.shape) == 2\n",
    "        self.n_train_ = n_train = K_XX.shape[0]\n",
    "        \n",
    "        if len(y.shape) == 1:\n",
    "            self.n_labels_ = None\n",
    "            y = y[:, None]\n",
    "        else:\n",
    "            assert len(y.shape) == 2\n",
    "            self.n_labels_ = y.shape[1]\n",
    "\n",
    "        assert K_XX.shape[1] == y.shape[0] == self.n_train_\n",
    "        \n",
    "        # TODO: find the solution, and save it in eg self.alpha_\n",
    "    \n",
    "    def predict(self, K_test):\n",
    "        \"\"\"\n",
    "        Predict the labels of a test set.\n",
    "        \n",
    "          K_test: The train-to-test kernel matrix, shape [n_train, n_test].\n",
    "        \n",
    "        Return: the vector of test predictions, shape [n_test].\n",
    "        \"\"\"\n",
    "        K_test = torch.as_tensor(K_test)\n",
    "        assert len(K_test.shape) == 2\n",
    "        assert K_test.shape[0] == self.n_train_\n",
    "        \n",
    "        # TODO: set preds to shape [n_test, n_labels]\n",
    "        \n",
    "        # return a vector if we were fit with a vector, matrix otherwise\n",
    "        return preds.squeeze(1) if self.n_labels_ is None else preds\n",
    "    \n",
    "    def mses(self, K_test, y_test, return_preds=False):\n",
    "        \"\"\"\n",
    "        Computes the mean squared error of each output for a test set.\n",
    "        \n",
    "          K_test: The train-to-test kernel matrix, shape [n_train, n_test].\n",
    "          y_test: The test labels, shape [n_train] or [n_train, n_labels]\n",
    "                  (agreeing with what was passed to fit()).\n",
    "                  \n",
    "        Returns a vector if y_test is 2d, or a scalar if not.\n",
    "        \"\"\"\n",
    "        preds = self.predict(K_test)\n",
    "        y_test = torch.as_tensor(y_test)\n",
    "        assert preds.shape == y_test.shape\n",
    "        errs = ((preds - y_test) ** 2).mean(0)\n",
    "        return (errs, preds) if return_preds else errs\n",
    "    \n",
    "    def mse(self, K_test, y_test, return_preds=False):\n",
    "        \"\"\"\n",
    "        Computes the mean squared error across outputs for a test set.\n",
    "        \n",
    "          K_test: The train-to-test kernel matrix, shape [n_train, n_test].\n",
    "          y_test: The test labels, shape [n_train] or [n_train, n_labels]\n",
    "                  (agreeing with what was passed to fit()).\n",
    "                  \n",
    "        Returns a scalar.\n",
    "        \"\"\"\n",
    "        errs, preds = self.mses(K_test, y_test, return_preds=True)\n",
    "        err = errs.mean()\n",
    "        return (err, preds) if return_preds else err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.717393Z",
     "iopub.status.busy": "2022-10-02T19:25:04.717052Z",
     "iopub.status.idle": "2022-10-02T19:25:04.718624Z",
     "shell.execute_reply": "2022-10-02T19:25:04.718870Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(krr, kernel_cls=None, plot=True,\n",
    "             X_train=None, y_train=None, X_test=None, y_test=None):\n",
    "    if X_train is None:\n",
    "        X_train = toy_X_train\n",
    "    if y_train is None:\n",
    "        y_train = toy_y_train\n",
    "    if X_test is None:\n",
    "        X_test = toy_X_test\n",
    "    if y_test is None:\n",
    "        y_test = toy_y_test\n",
    "    \n",
    "    plot_xs = np.linspace(0, 1, num=500)[:, None]\n",
    "    if kernel_cls is None:\n",
    "        kernel_cls = functools.partial(RBFKernel, sigma=0.05)\n",
    "    K = kernel_cls(X_train, X_test, plot_xs)\n",
    "\n",
    "    krr.fit(K.XX, y_train)\n",
    "    train_mse = krr.mse(K.XX, y_train).item()\n",
    "    test_mse = krr.mse(K.XY, y_test).item()\n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X_train[:, 0], y_train)\n",
    "        ax.plot(plot_xs, krr.predict(K.XZ).numpy(), lw=4, color='r')\n",
    "        ax.set_title(f\"Train MSE: {train_mse:.2} / Test MSE: {test_mse:.2}\")\n",
    "    else:\n",
    "        return train_mse, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.720953Z",
     "iopub.status.busy": "2022-10-02T19:25:04.720610Z",
     "iopub.status.idle": "2022-10-02T19:25:04.825624Z",
     "shell.execute_reply": "2022-10-02T19:25:04.825895Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=.001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what my solution looks like:\n",
    "![hi](figs/toy-krr-eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of $\\lambda$\n",
    "For this problem, we want a pretty small $\\lambda$, just enough to make it work, since the amount of inherent noise in the problem is fairly small. To check this, let's just try a bunch of different $\\lambda$s.\n",
    "\n",
    "(Note that the Cholesky solution is likely to crash with small $\\lambda$ before the `torch.solve` solution would, because \u2013 especially in the `float32` computation we're doing here \u2013\u00a0$K + n \\lambda I$ will appear singular. My results image below used the `torch.solve` version.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: What do you think will happen visually when you change $\\lambda$? Try a few different numbers for `reg_wt`, including increasing it really high, and see if it matches your intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.906342Z",
     "iopub.status.busy": "2022-10-02T19:25:04.905482Z",
     "iopub.status.idle": "2022-10-02T19:25:04.978788Z",
     "shell.execute_reply": "2022-10-02T19:25:04.979096Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:04.982772Z",
     "iopub.status.busy": "2022-10-02T19:25:04.982423Z",
     "iopub.status.idle": "2022-10-02T19:25:05.241424Z",
     "shell.execute_reply": "2022-10-02T19:25:05.241656Z"
    }
   },
   "outputs": [],
   "source": [
    "lams = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1]\n",
    "train_mses = []\n",
    "test_mses = []\n",
    "for lam in lams:\n",
    "    krr = KernelRidgeRegression(reg_wt=lam)\n",
    "    try:\n",
    "        train, test = evaluate(krr, plot=False)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"{lam}: {e}\")\n",
    "        train = test = np.nan\n",
    "    train_mses.append(train)\n",
    "    test_mses.append(test)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(lams, train_mses, marker='o', label='train MSE')\n",
    "ax.plot(lams, test_mses, marker='o', label='test MSE')\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(r'$\\lambda$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My results, for reference, look like:\n",
    "![](figs/toy-krr-lambda.png)\n",
    "\n",
    "My Cholesky solution failed for $\\lambda = 10^{-7}$, so your plot might cut off the first points, or behave a little differently. In my plot at least, we can actually tell that the behavior for the smallest values of $\\lambda$ is numerical error, not overfitting: overfitting would increase the test error as we decrease $\\lambda$, but it shouldn't increase the training error. (We can see a mild amount of overfitting happening at $\\lambda = 10^{-6}$ here: train error is a little lower, but test error has ticked up a tiny bit.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the kernel\n",
    "\n",
    "We can also see whether my guess at $\\sigma$ was really right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** First, what happens when you change $\\sigma$? Try some numbers, including much larger and much smaller ones, and see if it looks like what you expect to happen. See how this interacts with setting $\\lambda$ as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:05.244085Z",
     "iopub.status.busy": "2022-10-02T19:25:05.243704Z",
     "iopub.status.idle": "2022-10-02T19:25:05.323442Z",
     "shell.execute_reply": "2022-10-02T19:25:05.323683Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=.001),\n",
    "         kernel_cls=functools.partial(RBFKernel, sigma=.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** What happens if you use `LinearKernel`? `PolynomialKernel`, with different `degree`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:05.326176Z",
     "iopub.status.busy": "2022-10-02T19:25:05.325715Z",
     "iopub.status.idle": "2022-10-02T19:25:05.393701Z",
     "shell.execute_reply": "2022-10-02T19:25:05.393895Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=.001),\n",
    "         kernel_cls=functools.partial(LinearKernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to `RBFKernel`, let's do a joint search over $\\lambda$ and $\\sigma$, since they'll interact with one another:\n",
    "\n",
    "(No need to worry about the particulars of this code: it's just calling `KernelRidgeRegression` for a grid of `lams` and `sigs`, then plotting the results. Also, if you get some matplotlib warnings, don't worry about it; they're just slightly fiddly to work around.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:05.399913Z",
     "iopub.status.busy": "2022-10-02T19:25:05.399562Z",
     "iopub.status.idle": "2022-10-02T19:25:06.032731Z",
     "shell.execute_reply": "2022-10-02T19:25:06.032928Z"
    }
   },
   "outputs": [],
   "source": [
    "lams = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0]\n",
    "sigs = [.001, .01, .05, .1, .25, .5, 1]\n",
    "mses = np.full((len(lams), len(sigs), 2), np.nan)\n",
    "\n",
    "for lam_i, lam in enumerate(lams):\n",
    "    for sig_i, sig in enumerate(sigs):\n",
    "        krr = KernelRidgeRegression(reg_wt=lam)\n",
    "        try:\n",
    "            mses[lam_i, sig_i, :] = evaluate(\n",
    "                krr, functools.partial(RBFKernel, sigma=sig), plot=False)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"{lam} {sig}: {e}\")\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(8, 4), constrained_layout=True)\n",
    "\n",
    "norm = mpl.colors.LogNorm(vmin=np.nanmin(mses), vmax=np.nanmax(mses))\n",
    "\n",
    "ax1, ax2 = axes\n",
    "ax1.grid(False)\n",
    "ax1.matshow(mses[:, :, 0], norm=norm)\n",
    "best1, best2 = np.unravel_index(np.argmin(mses[:, :, 0]), mses.shape[:2])\n",
    "ax1.scatter([best2], [best1], marker='o', color='c', s=100)\n",
    "ax1.set_title(f\"Train MSE: min {mses[best1, best2, 0]:.3}\")\n",
    "\n",
    "ax2.grid(False)\n",
    "im = ax2.matshow(mses[:, :, 1], norm=norm)\n",
    "best1, best2 = np.unravel_index(np.argmin(mses[:, :, 1]), mses.shape[:2])\n",
    "ax2.scatter([best2], [best1], marker='o', color='c', s=100)\n",
    "ax2.set_title(f\"Test MSE: min {mses[best1, best2, 1]:.3}\")\n",
    "fig.colorbar(im)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(False)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(1))\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.xaxis.set_ticklabels([''] + [f'{sig}' for sig in sigs])\n",
    "    ax.set_xlabel(r'$\\sigma$')\n",
    "    \n",
    "    ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_ticklabels([''] + [f'{lam}' for lam in lams])\n",
    "    ax.set_ylabel(r'$\\lambda$')\n",
    "    \n",
    "# If you get a RuntimeWarning due to nans, don't worry about it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, my result looks like\n",
    "![](figs/toy-krr-sig-lambda.png)\n",
    "Smaller $\\sigma$ can get lower training error, but the best test error is definitely with $\\sigma = 0.05$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting `y`\n",
    "\n",
    "What do you think will happen if we fit with `y` replaced by `y + 100`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:06.035187Z",
     "iopub.status.busy": "2022-10-02T19:25:06.034863Z",
     "iopub.status.idle": "2022-10-02T19:25:06.108348Z",
     "shell.execute_reply": "2022-10-02T19:25:06.108632Z"
    }
   },
   "outputs": [],
   "source": [
    "# normal fit, for comparison\n",
    "evaluate(KernelRidgeRegression(reg_wt=.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:06.111096Z",
     "iopub.status.busy": "2022-10-02T19:25:06.110726Z",
     "iopub.status.idle": "2022-10-02T19:25:06.203479Z",
     "shell.execute_reply": "2022-10-02T19:25:06.203836Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit with labels shifted upwards by 100\n",
    "evaluate(KernelRidgeRegression(reg_wt=.001),\n",
    "         y_train=toy_y_train + 100, y_test=toy_y_test + 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "think"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"font-size: 3em\">\ud83e\udd14</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"font-size: 3em\">\ud83e\udd14</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"font-size: 3em\">\ud83e\udd14</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that in traditional linear regression, you fit $y = w \\cdot x + b$. Here, we're using $y = w \\cdot \\varphi(x)$; no $+ b$. Unlike in traditional linear regression, the kernel can more-or-less account for it, but the weird thing at the end \u2013\u00a0and the overall downward trend \u2013\u00a0could be fixed by adding an offset.\n",
    "\n",
    "The easiest way to do that is to add an additional dimension to $\\varphi(x)$ that's just a constant $1$, so that the corresponding element of $w$ can be $b$. Since $k(x, y) = \\varphi(x) \\cdot \\varphi(y)$, this means that we just add 1 to the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:06.207211Z",
     "iopub.status.busy": "2022-10-02T19:25:06.206873Z",
     "iopub.status.idle": "2022-10-02T19:25:06.208074Z",
     "shell.execute_reply": "2022-10-02T19:25:06.208364Z"
    }
   },
   "outputs": [],
   "source": [
    "class RBFKernelPlusOne(RBFKernel):\n",
    "    def _compute(self, *args):\n",
    "        return super()._compute(*args) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:06.210799Z",
     "iopub.status.busy": "2022-10-02T19:25:06.210446Z",
     "iopub.status.idle": "2022-10-02T19:25:06.289356Z",
     "shell.execute_reply": "2022-10-02T19:25:06.289723Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=.001),\n",
    "         kernel_cls=functools.partial(RBFKernelPlusOne, sigma=.05),\n",
    "         y_train=toy_y_train + 100, y_test=toy_y_test + 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note: traditional ridge regression regularizes with $\\lambda \\lVert w \\rVert^2$, and leaves $b$ unregularized. This has nice properties like making the fit shift _exactly_ along with an offset $y$. By adding 1 to the kernel, though, ours will _slightly_ change with offsets, because we're also effectively regularizing with $\\lambda b^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:06.292379Z",
     "iopub.status.busy": "2022-10-02T19:25:06.291986Z",
     "iopub.status.idle": "2022-10-02T19:25:06.369353Z",
     "shell.execute_reply": "2022-10-02T19:25:06.369547Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=.001),\n",
    "         kernel_cls=functools.partial(RBFKernelPlusOne, sigma=.05),\n",
    "         y_train=toy_y_train + 5000, y_test=toy_y_test + 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few ways to resolve this:\n",
    "\n",
    "1. Actually add an unregularized offset into the model and work it out properly. Unfortunately, this actually breaks some of the RKHS stuff; if you're so inclined, it's an interesting exercise to work out what happens here.\n",
    "2. Mitigate the scaling by adding a large constant, instead of 1; if you add $c$, then the regularization on $b$ is effectively $\\lambda {b^2}/{c^2}$.\n",
    "3. Just subtract the mean of `y_train` before passing it into the model, then add it on to predictions later.\n",
    "\n",
    "People normally do option 3 in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A harder problem\n",
    "\n",
    "Okay, that problem was too easy. Let's do something slighty more interesting.\n",
    "\n",
    "Not _too_ interesting, though; we'll start with the MNIST dataset of handwritten images, with the goal of identifying which digit an image is. (We're building up!)\n",
    "\n",
    "But this is a classification dataset, and we're doing ridge regression right now, you say!\n",
    "\n",
    "That's true. You'd probably do better to use an actual classification loss. But we're going to just do regression to \"one-hot\" labels, that is the label for an image of a handwritten 0 will be\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    ".$$\n",
    "We're going to use our multi-output support for RidgeRegression that we implemented before to train 10 different regression models: one that predicts the degree of zero-ness of an image, one for the one-ness, etc.\n",
    "\n",
    "(This is sometimes called the [Brier score](https://en.wikipedia.org/wiki/Brier_score#Original_definition_by_Brier), and it is a [proper scoring rule](https://en.wikipedia.org/wiki/Scoring_rule#ProperScoringRules). So, yes, you could get better performance from other losses, but this one is at least well-posed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:06.373453Z",
     "iopub.status.busy": "2022-10-02T19:25:06.370820Z",
     "iopub.status.idle": "2022-10-02T19:25:06.402066Z",
     "shell.execute_reply": "2022-10-02T19:25:06.401862Z"
    }
   },
   "outputs": [],
   "source": [
    "# some utilities for pytorch datasets\n",
    "\n",
    "def read(ds, batch_size=None, **kwargs):\n",
    "    if batch_size is None:\n",
    "        batch_size = len(ds)\n",
    "    return next(iter(DataLoader(ds, batch_size=batch_size, **kwargs)))\n",
    "\n",
    "def random_subset(ds, n):\n",
    "    return torch.utils.data.random_split(ds, [n, len(ds) - n])[0]\n",
    "\n",
    "MNIST = functools.partial(\n",
    "    torchvision.datasets.MNIST,\n",
    "    root='data',\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        lambda t: t.reshape(784),\n",
    "    ]),\n",
    "    target_transform=lambda y:\n",
    "        torch.nn.functional.one_hot(torch.as_tensor(y), num_classes=10).float()\n",
    ")\n",
    "\n",
    "mnist_train = MNIST(train=True)\n",
    "mnist_test = MNIST(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:06.406773Z",
     "iopub.status.busy": "2022-10-02T19:25:06.406485Z",
     "iopub.status.idle": "2022-10-02T19:25:06.471254Z",
     "shell.execute_reply": "2022-10-02T19:25:06.471464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just look at some data points\n",
    "X, y = read(mnist_train, batch_size=100, shuffle=True)\n",
    "pil_grid(X.reshape(-1, 1, 28, 28), nrow=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST has 60,000 images. Even constructing a, say, 50,000 $\\times$ 50,000 matrix is maybe too much, so for now, let's try training on a random subset first, though, to (a) check that our multi-output implementation works, and (b) set a baseline to compare to for the other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:06.473430Z",
     "iopub.status.busy": "2022-10-02T19:25:06.472680Z",
     "iopub.status.idle": "2022-10-02T19:25:08.551361Z",
     "shell.execute_reply": "2022-10-02T19:25:08.551580Z"
    }
   },
   "outputs": [],
   "source": [
    "# get a subset of the data\n",
    "train_X, train_y = read(mnist_train, 5_000, shuffle=True)\n",
    "test_X, test_y = read(mnist_test, 5_000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:08.555224Z",
     "iopub.status.busy": "2022-10-02T19:25:08.554828Z",
     "iopub.status.idle": "2022-10-02T19:25:08.556144Z",
     "shell.execute_reply": "2022-10-02T19:25:08.556642Z"
    }
   },
   "outputs": [],
   "source": [
    "def clf_eval(truth, preds, label_names=None):\n",
    "    if label_names is None:\n",
    "        label_names = np.arange(truth.shape[1]).astype(str)\n",
    "        \n",
    "    # want integers instead of one-hot\n",
    "    truth = truth.argmax(1)\n",
    "    preds = preds.argmax(1)\n",
    "    \n",
    "    ax = plot_confusion_matrix(truth, preds, label_names, rotation=0, figsize=(7, 6))\n",
    "    fig = ax.figure\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    report = sklearn.metrics.classification_report(\n",
    "        truth, preds, target_names=label_names, zero_division=0)\n",
    "    display(HTML(f'<pre>{report}</pre>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:08.559132Z",
     "iopub.status.busy": "2022-10-02T19:25:08.558707Z",
     "iopub.status.idle": "2022-10-02T19:25:09.733694Z",
     "shell.execute_reply": "2022-10-02T19:25:09.734003Z"
    }
   },
   "outputs": [],
   "source": [
    "K = RBFKernelPlusOne(train_X, test_X)\n",
    "\n",
    "krr = KernelRidgeRegression(reg_wt=1e-5)\n",
    "krr.fit(K.XX, train_y)\n",
    "test_preds = krr.predict(K.XY)\n",
    "\n",
    "clf_eval(test_y, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah....that wasn't great. We forgot to set the kernel bandwidth.\n",
    "\n",
    "A usual heuristic to start with is the median distance between data points.\n",
    "\n",
    "**Exercise:** compute the median distance between training data points. You can either compute this yourself, or use predefined functions, whichever you'd prefer. If it's too slow to compute, you can subsample the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:09.739088Z",
     "iopub.status.busy": "2022-10-02T19:25:09.738017Z",
     "iopub.status.idle": "2022-10-02T19:25:10.066775Z",
     "shell.execute_reply": "2022-10-02T19:25:10.067268Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: find med_sigma\n",
    "med_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:10.072584Z",
     "iopub.status.busy": "2022-10-02T19:25:10.072154Z",
     "iopub.status.idle": "2022-10-02T19:25:11.020308Z",
     "shell.execute_reply": "2022-10-02T19:25:11.020660Z"
    }
   },
   "outputs": [],
   "source": [
    "K = RBFKernelPlusOne(train_X, test_X, sigma=med_sigma)\n",
    "\n",
    "krr = KernelRidgeRegression(reg_wt=1e-5)\n",
    "krr.fit(K.XX, train_y)\n",
    "test_preds = krr.predict(K.XY)\n",
    "\n",
    "clf_eval(test_y, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! I got 96% accuracy, which is pretty reasonable. (You can do better with a convnet, of course, but not bad for such a simple model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these predictions aren't actually valid probabilities, which is slightly annoying: as you can see, we're getting numbers below 0 and above 1. Whether this is important depends on your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:11.028219Z",
     "iopub.status.busy": "2022-10-02T19:25:11.027905Z",
     "iopub.status.idle": "2022-10-02T19:25:11.091885Z",
     "shell.execute_reply": "2022-10-02T19:25:11.092128Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(test_preds.numpy().ravel(), bins='auto', histtype='stepfilled');\n",
    "plt.axvline(0, color='r')\n",
    "plt.axvline(1, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, maybe we can do better by picking a different $\\sigma$ than the median? And what about the arbitrary choice of regularization weight?\n",
    "\n",
    "We could do a grid search like before, but let's do something more fun: gradient descent!\n",
    "\n",
    "We want to find the derivative of the validation error with respect to $\\sigma$ and $\\lambda$. That is,\n",
    "$$\n",
    "\\nabla_{\\sigma\\lambda} \\frac{1}{n^\\text{val}} \\sum_{i=1}^{n^\\text{val}} \\lVert\n",
    "    \\hat{y}_{X_\\text{train},\\sigma,\\lambda}(X_i^\\text{val}) - y_i^\\text{val}\n",
    "\\rVert^2\n",
    ",$$\n",
    "where $\\hat{y}_{X_\\text{train},\\sigma,\\lambda}$ is the predictor trained with $X_\\text{train}$ using kernel bandwidth $\\sigma$ and regularization $\\lambda$.\n",
    "\n",
    "(Although $\\hat y$ fundamentally uses the square loss, we could conceivably use another \"outer\" loss. But since $\\hat y$ isn't a distribution, we can't use cross-entropy or similar losses, so square loss is a reasonable choice. If we really wanted, we could e.g. learn an affine transformation of these outputs and then apply a softmax to them to get valid probabilities in the end.)\n",
    "\n",
    "Because we have a PyTorch expression for the whole process of $\\hat{y}$, we can just take derivatives. We'll paramaterize with $\\log \\lambda$ and $\\log \\sigma$, though, to avoid invalid values (and because it's probably a better domain for each anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:11.104889Z",
     "iopub.status.busy": "2022-10-02T19:25:11.099376Z",
     "iopub.status.idle": "2022-10-02T19:25:34.515006Z",
     "shell.execute_reply": "2022-10-02T19:25:34.515195Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "# You can use a GPU here if you want, but you have to have been careful about\n",
    "# managing the device of tensors in your implementation or it might crash.\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "log_lam = torch.tensor(np.log(1e-4), requires_grad=True, device=device)\n",
    "log_sig = torch.tensor(np.log(med_sigma), requires_grad=True, device=device)\n",
    "opt = torch.optim.SGD([log_lam, log_sig], lr=1)  # feel free to fiddle with\n",
    "\n",
    "trace = []\n",
    "\n",
    "n_steps = 100 # Feel free to increase...\n",
    "with tqdm(range(n_steps)) as bar:\n",
    "    for i in bar:\n",
    "        opt.zero_grad()  # reset gradient state before computing things\n",
    "        \n",
    "        lam = torch.exp(log_lam)\n",
    "        sig = torch.exp(log_sig)\n",
    "\n",
    "        # Fitting on the full training set is a little slow,\n",
    "        # so let's subsample.\n",
    "        # Also, since we're optimizing parameters based on fit performance,\n",
    "        # we should evaluate on points from the *training set*.\n",
    "        \n",
    "        batches = iter(DataLoader(mnist_train, batch_size=500, shuffle=True))\n",
    "        sub_train_X, sub_train_y = [x.to(device) for x in next(batches)]\n",
    "        sub_val_X, sub_val_y = [x.to(device) for x in next(batches)]\n",
    "        \n",
    "        # compute the loss on the validation set\n",
    "        krr = KernelRidgeRegression(reg_wt=lam)\n",
    "        K = RBFKernelPlusOne(sub_train_X, sub_val_X, sigma=sig)\n",
    "        krr.fit(K.XX, sub_train_y)\n",
    "        loss = krr.mse(K.XY, sub_val_y)\n",
    "\n",
    "        loss.backward()  # compute the gradients\n",
    "        opt.step()       # update lam / sig following the gradients\n",
    "        lam_val = lam.cpu().item()\n",
    "        sig_val = sig.cpu().item()\n",
    "        loss_val = loss.cpu().item()\n",
    "        trace.append((i, lam_val, sig_val, loss_val))\n",
    "        bar.set_postfix(lam=f\"{lam_val:.4}\", sig=f\"{sig_val:.4}\", loss=f\"{loss_val:.4}\")\n",
    "\n",
    "fig, (a1, a2, a3) = plt.subplots(ncols=3, figsize=(16, 4), constrained_layout=True)\n",
    "inds, lams, sigs, losses = np.asarray(trace).T\n",
    "\n",
    "a1.plot(inds, losses)\n",
    "a1.set_title(\"MSE\")\n",
    "\n",
    "a2.plot(inds, lams)\n",
    "a2.set_title(r\"$\\lambda$\")\n",
    "a2.set_yscale('log')\n",
    "\n",
    "a3.plot(inds, losses)\n",
    "a3.set_title(r\"$\\sigma$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it actually does better with a slightly smaller bandwidth (and a smaller $\\lambda$).\n",
    "\n",
    "One caveat to this is that the optimal parameters will generally depend on $n$; here we're finding the best parameters for a fit on 500 training points, but you might want smaller $\\lambda$ and $\\sigma$ as $n$ grows.\n",
    "\n",
    "Since the loss landscape is surely nonconvex, it might be better to combine grid search and local gradient descent, starting from various locations. We could of course try other optimizers too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Did this optimization help the MSE that it's optimizing on the test set (`mnist_test`) versus our heuristic guess before? What about the classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">At this point, you've finished the baseline of this chunk of the tutorial.<sup>(Don't you feel smarter?)</sup></span>\n",
    "    \n",
    "<span style=\"color: blue\">There are now some more-or-less independent sections remaining for the ridge regression component; feel free to do whichever you feel like of them, in any order.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave-one-out cross-validation is where you fit on $n-1$ data points and test on the remaining one, loop over the dataset so each point is left out one time, and use that as an estimate of your generalization error. Compared to using a single validation set like above, it lets you get good hyperparameters for $n-1$ data points rather than, say, $0.8n$ data points, and it also lets every point serve as a validation point \u2013\u00a0but it's averaging over $n$ very dependent estimates (they're all fit on _almost_ the same dataset), so it's not actually always better than doing, say, 5-fold CV.\n",
    "\n",
    "For ridge regression, the leave-one-out cross-validation error is actually possible to find in closed form, by doing the regression on all $n$ data points then doing a rank-one update to remove a single data point at a time. It works out to (see e.g. Theorem 3.2 [here](https://openreview.net/pdf?id=7grkzyj89A_), though the result is classical)\n",
    "$$\n",
    "L_\\mathit{loo} = \\frac1n \\sum_{i=1}^n \\left( \\frac{y_i - \\hat f_{\\!\\lambda}(X_i)}{1 - A_{ii}} \\right)^2\n",
    "$$\n",
    "where $\\hat f_{\\!\\lambda}$ is the ridge regression estimate on the full data,\n",
    "and the matrix $A$ is given by $K (K + n \\lambda I)^{-1}$.\n",
    "If you want,\n",
    "implement this loss, verify that it agrees with manually doing leave-one-out regression,\n",
    "and change to use that instead of the single train-val split below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exploration of the kernel for ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some more open-ended questions you might want to explore at this point (but also consider going on to the remaining sections of the tutorial.\n",
    "\n",
    "**Note:** MNIST might be too easy to really look into these (since we're already at 96% accuracy with the most basic thing). You could try `torchvision.datasets.FashionMNIST` or `torchvision.datasets.CIFAR10`. (Pass `root='data', download=True` to get them if necessary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Try other kernels than the Gaussian RBF on this data. Some that might be interesting:\n",
    "\\begin{align}\n",
    "\\exp\\left( -\\frac12 \\left(\\frac{\\lVert x - y \\rVert}{\\ell}\\right)^\\beta \\right)\n",
    "&\\qquad\\text{ for $0 < \\beta \\le 2$ ($\\beta = 2$ is Gaussian, $\\beta = 1$ is Laplacian)}\n",
    "\\\\\n",
    "\\lVert x - z_0 \\rVert + \\lVert y - z_0 \\rVert - \\lVert x - y \\rVert\n",
    "&\\qquad\\text{ for any $z_0$ (\"distance kernel\")}\n",
    "\\\\\n",
    "\\frac{1}{\\sqrt{\\lVert x - y \\rVert^2 + c}}\n",
    "&\\qquad\\text{ (inverse multiquadric)}\n",
    "\\\\\n",
    "\\left( 1 + \\frac{\\lVert x - y \\rVert^2}{2 \\alpha \\ell^2} \\right)^{-\\alpha}\n",
    "&\\qquad\\text{ (rational quadratic; $\\alpha \\to \\infty$ becomes Gaussian)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Does it work if you start at a bad value of the hyperparameters? Is this behavior different between choices of kernel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** All of the kernels above are based on plain Euclidean distances between images. What if you did something different? For example, $\\lVert A (x - y) \\rVert$ for a learned transformation matrix $A$?\n",
    "\n",
    "**Exercise:** What about $k(x, y) = \\kappa( \\phi(x), \\phi(y) )$, where $\\kappa$ is one of the kernels above and $\\phi$ is a learned network? (We'll also explore this a little bit in the meta-learning section below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced kernel ridge regression: kernel approximation\n",
    "\n",
    "Because MNIST is too big to fit directly, we were just subsampling.\n",
    "\n",
    "In a previous, longer version of this course, we discussed two approximations for this setting:\n",
    "\n",
    "- _Nystr\u00f6m_, instead of finding $f(x) = \\sum_{i=1}^n \\alpha_i k(X_i, x)$,\n",
    "finds $f(x) = \\sum_{i=1}^m \\alpha_i k(\\tilde X_i, x)$.\n",
    "It's a fairly quick generalization of the argument we did in lecture for regular ridge regression to find the optimal $\\alpha_i$ given the choice of $\\tilde X_i$.\n",
    "You can pick the $\\tilde X_i$ in various ways:\n",
    "uniformly,\n",
    "according to a $k$-means clustering on the original $X_i$,\n",
    "by approximate leverage scores,\n",
    "or more.\n",
    "You could even optimize the $\\tilde X_i$ with gradient descent if you wanted,\n",
    "since we know how to do that;\n",
    "that makes the model something like a classical RBF net.\n",
    "\n",
    "- _Random Fourier features_ find a linear function in the feature space $\\cos(\\omega_i^T x)$, $\\sin(\\omega_i^T x)$, where the $\\omega$ are sampled from the Fourier transform of the kernel. For a Gaussian RBF kernel with bandwidth $\\sigma$, this is a Gaussian distribution with mean 0 and variance $\\frac{1}{\\sigma^2} I$.\n",
    "\n",
    "**Exercise:** Implement and compare ridge regression with Nystr\u00f6m and random Fourier features to the full kernel ridge regression based on subsampled data we've been using so far. You'll probably want to implement a \"primal\" ridge regression class, based on\n",
    "$$\\hat w = (X^T X + \\lambda I)^{-1} X^T y;$$\n",
    "here $X^T X$ is the covariance matrix, while $X X^T$ would be the kernel matrix.\n",
    "Once you have that working, you can make subclasses to handle the different kinds of features. \n",
    "\n",
    "**Exercise:** How does each method \u2013\u00a0Nystr\u00f6m, RFF, just subsampling \u2013 improve in accuracy as you give it more computation budget?  (A simple way to approximate computation would be to equalize the size of the basis / training subset. Or you could actually measure the time it takes.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced ridge regression: Meta-learning\n",
    "\n",
    "<span style=\"color: red\">You probably want a GPU for this section. You can use Colab; see the link at the top.</span> If you're switching to Colab, you can either upload your version of this notebook or just copy-paste over your kernel class and KernelRidgeRegression implementation.\n",
    "\n",
    "MNIST has only 10 categories of image, and thousands of examples of each. It's not the most interesting of problems.\n",
    "\n",
    "[Omniglot](https://github.com/brendenlake/omniglot) is \"MNIST transpose\": it has 20 examples each of 1,623 characters (from 50 different alphabets).\n",
    "\n",
    "![](figs/omniglot_grid.jpg)\n",
    "\n",
    "Since there are only 20 examples per class, simple methods like ridge regression with Gaussian kernels aren't going to work very well. But humans are generally able to recognize these categories, even from an alphabet they've never seen before, based on one or a few examples.\n",
    "\n",
    "One popular problem in this area is called meta-learning, \"learning to learn\" \u2013 to find a learning algorithm such that given a few examples of a new character, we can quickly learn to recognize it.\n",
    "\n",
    "You might guess, based on what notebook this is coming at the end of, that one way to do this is to learn a kernel for ridge regression. The goal is to find a kernel such that, given a new type of character, you can quickly learn an effective classifier. (This was done by [Bertinetto et al. (ICLR 2019)](http://arxiv.org/abs/1805.08136); they called it Ridge Regression Differentiable Discriminator, R2-D2.)\n",
    "\n",
    "Specifically, we're going to use a \"deep kernel\" of the form\n",
    "$$\n",
    "k(x, y) = \\kappa( \\phi(x), \\phi(y) )\n",
    ",$$\n",
    "where $\\phi$ is a deep network and $\\kappa$ is some standard fixed kernel. Bertinetto et al. used $\\kappa(a, b) = a^T b$, putting all the work on the deep network $\\phi$, but we can also try playing around with other choices for $\\kappa$. Bertinetto et al. used a four-layer convolutional $\\phi$, implemented in `support.R2D2Featurizer`. (It gives 3,584-dimensional  features, so a Gaussian kernel on top might have some issues.)\n",
    "\n",
    "The training procedure is set up in \"episodes\":\n",
    "- Sample $N$ classes from the dataset.\n",
    "- Train ridge regression on $K$ examples (\"shots\") from each class.\n",
    "- Test on $Q$ test examples (\"queries\") from each class.\n",
    "- Update the learner parameters (kernel weights, regularization $\\lambda$) to follow the gradient of this test loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:34.518073Z",
     "iopub.status.busy": "2022-10-02T19:25:34.517770Z",
     "iopub.status.idle": "2022-10-02T19:25:34.706846Z",
     "shell.execute_reply": "2022-10-02T19:25:34.707013Z"
    }
   },
   "outputs": [],
   "source": [
    "# Following Vinyals et al. (2016), Bertinetto et al. augment Omniglot\n",
    "# by adding classes corresponding to rotations of the other classes.\n",
    "# This class does that.\n",
    "\n",
    "sz = 28\n",
    "omniglot = support.CombinedOmniglot(\n",
    "    'data',\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((sz, sz)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        lambda t: 1 - t,  # make it white-on-black like MNIST\n",
    "    ]),\n",
    "    rotations=[0, 90, 180, 270],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:34.710119Z",
     "iopub.status.busy": "2022-10-02T19:25:34.709830Z",
     "iopub.status.idle": "2022-10-02T19:25:34.753881Z",
     "shell.execute_reply": "2022-10-02T19:25:34.754097Z"
    }
   },
   "outputs": [],
   "source": [
    "n_r = omniglot.n_rotations\n",
    "for i in [967, 1003]:\n",
    "    rots = torch.utils.data.ConcatDataset([\n",
    "        omniglot.class_subset(omniglot.construct_class_id(i, r)) for r in range(n_r)\n",
    "    ])\n",
    "    X, y = read(rots)\n",
    "    assert (omniglot.decompose_class_id(y)[0] == i).all()\n",
    "    display(pil_grid(X, nrow=omniglot.n_per_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:34.758027Z",
     "iopub.status.busy": "2022-10-02T19:25:34.757716Z",
     "iopub.status.idle": "2022-10-02T19:25:34.758798Z",
     "shell.execute_reply": "2022-10-02T19:25:34.759087Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_episode(n_shots=5, n_classes=60, total_batch_size=600):\n",
    "    per_class = total_batch_size // n_classes\n",
    "    n_extra = omniglot.n_per_class - per_class\n",
    "    assert n_extra >= 0\n",
    "    assert total_batch_size % n_classes == 0\n",
    "    assert n_shots < per_class\n",
    "    \n",
    "    base_class_ids = np.random.choice(training_base_classes, size=n_classes, replace=False)\n",
    "    rotation_ids = np.random.randint(omniglot.n_rotations, size=n_classes)\n",
    "    class_ids = [\n",
    "        omniglot.construct_class_id(b, r) for b, r in zip(base_class_ids, rotation_ids)\n",
    "    ]\n",
    "    n_shots = np.random.choice([1, 5])\n",
    "    n_query = per_class - n_shots\n",
    "\n",
    "    parts = [\n",
    "        torch.utils.data.random_split(\n",
    "            omniglot.class_subset(class_id),\n",
    "            [int(n) for n in [n_shots, n_query, n_extra]]\n",
    "            # these are np.int64s, need to make ints...sigh\n",
    "        )[:2]\n",
    "        for class_id in class_ids\n",
    "    ]\n",
    "    train_ds, query_ds = [torch.utils.data.ConcatDataset(ps) for ps in zip(*parts)]\n",
    "\n",
    "    train_X, train_y = read(train_ds)\n",
    "    query_X, query_y = read(query_ds)\n",
    "    \n",
    "    return train_X, train_y, query_X, query_y, np.asarray(class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:34.761691Z",
     "iopub.status.busy": "2022-10-02T19:25:34.761400Z",
     "iopub.status.idle": "2022-10-02T19:25:34.762615Z",
     "shell.execute_reply": "2022-10-02T19:25:34.762799Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_onehot(y, *other_ys):\n",
    "    # We want one-hot matrices, but only for the labels we actually have.\n",
    "    onehotter = sklearn.preprocessing.OneHotEncoder(\n",
    "        categories='auto', dtype=np.float32, sparse=False)\n",
    "    y = torch.as_tensor(onehotter.fit_transform(y[:, None]))\n",
    "    other_ys = [torch.as_tensor(onehotter.transform(oth[:, None]), device=device)\n",
    "                for oth in other_ys]\n",
    "    \n",
    "    def convert_back(labels):\n",
    "        \"Converts integers in the onehot output space to integers in onehot input space.\"\n",
    "        return torch.as_tensor(onehotter.categories_[0], device=labels.device)[labels]\n",
    "    \n",
    "    return [y] + other_ys, convert_back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the featurizing kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:34.764616Z",
     "iopub.status.busy": "2022-10-02T19:25:34.764299Z",
     "iopub.status.idle": "2022-10-02T19:25:34.765555Z",
     "shell.execute_reply": "2022-10-02T19:25:34.765822Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:34.767629Z",
     "iopub.status.busy": "2022-10-02T19:25:34.767291Z",
     "iopub.status.idle": "2022-10-02T19:25:34.768750Z",
     "shell.execute_reply": "2022-10-02T19:25:34.768928Z"
    }
   },
   "outputs": [],
   "source": [
    "training_base_classes, testing_base_classes = model_selection.train_test_split(\n",
    "    np.arange(omniglot.n_base_classes), test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:34.770837Z",
     "iopub.status.busy": "2022-10-02T19:25:34.770500Z",
     "iopub.status.idle": "2022-10-02T19:25:34.782412Z",
     "shell.execute_reply": "2022-10-02T19:25:34.782599Z"
    }
   },
   "outputs": [],
   "source": [
    "featurizer = support.R2D2Featurizer().to(device)\n",
    "\n",
    "def composite_kernel(*parts):\n",
    "    return LinearKernel(*[featurizer(p) for p in parts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** implement the fitting and training loop, using the `load_episode` helper above. You might find the `convert_to_onehot` function useful as well, and the `convert_back` function it returns could be helpful to compute accuracies.\n",
    "\n",
    "Hint: If you're not super experienced in PyTorch, the training loop for optimizng `sigma`/`lambda` above might be a useful reference. When constructing the optimizer, `list(featurizer.parameters())` gives you a list of all the parameters inside `featurizer`. You might also want to try `torch.optim.Adam` instead of `SGD` (or not).\n",
    "\n",
    "If you get errors about `cuda.FloatTensor` versus regular `FloatTensor`s, you might have to add a `device` argument somewhere, e.g. to the `torch.eye` inside your `KernelRidgeRegression.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:34.784768Z",
     "iopub.status.busy": "2022-10-02T19:25:34.784456Z",
     "iopub.status.idle": "2022-10-02T19:25:34.785663Z",
     "shell.execute_reply": "2022-10-02T19:25:34.785845Z"
    }
   },
   "outputs": [],
   "source": [
    "log_lam = torch.tensor(0.1, requires_grad=True, device=device)\n",
    "opt = torch.optim.Adam([log_lam] + list(featurizer.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T19:25:34.791246Z",
     "iopub.status.busy": "2022-10-02T19:25:34.790447Z",
     "iopub.status.idle": "2022-10-02T19:25:41.362669Z",
     "shell.execute_reply": "2022-10-02T19:25:41.362426Z"
    }
   },
   "outputs": [],
   "source": [
    "with tqdm(range(1)) as bar:  # obviously you should run for more than one step :)\n",
    "    for episode_i in bar:\n",
    "        # load an episode\n",
    "        train_X, train_y, query_X, query_y, class_ids = load_episode(\n",
    "            n_shots=np.random.choice([1, 5]),\n",
    "            total_batch_size=600,\n",
    "            n_classes=60,\n",
    "        )\n",
    "        train_X = train_X.to(device)\n",
    "        query_X = query_X.to(device)\n",
    "        (train_y_onehot, query_y_onehot), convert_back = convert_to_onehot(train_y, query_y)\n",
    "        train_y_onehot = train_y_onehot.to(device)\n",
    "        query_y_onehot = query_y_onehot.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        K = composite_kernel(train_X, query_X)\n",
    "        krr = KernelRidgeRegression(reg_wt=torch.exp(log_lam))\n",
    "        krr.fit(K.XX, train_y_onehot)\n",
    "        loss, preds = krr.mse(K.XY, query_y_onehot, return_preds=True)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        # compute accuracy\n",
    "        preds_cls = convert_back(preds.argmax(1))\n",
    "        acc = (preds_cls == query_y).sum().float() / query_y.shape[0]\n",
    "        \n",
    "        bar.set_postfix(loss=loss.item(), lam=torch.exp(log_lam).item(), acc=acc.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Play around with different kernels, including different featurizers. The source for `R2D2Featurizer` is in [`support/r2d2_featurizer.py`](support/r2d2_featurizer.py) if you want to build off that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you have a decent GPU and some time:** Try a more complicated dataset; miniImageNet or CIFAR-FS. I didn't set these up for you, so this will take more effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More complicated exercise:** A more effective way to do meta-learning for classification \u2013 that still uses kernels! \u2013\u00a0is [MetaOptNet](https://arxiv.org/abs/1904.03758). In that case, they use SVM classifiers, where the solver is not easy to differentiate through \u2013\u00a0but you can still find the derivative, because it's a convex problem, and you can differentiate the KKT conditions. (Their code, in PyTorch, is at [`kjunelee/MetaOptNet`](https://github.com/kjunelee/MetaOptNet).) This approach was later made *much* simpler to implement with the [`cvxpylayers`](https://github.com/cvxgrp/cvxpylayers) library. Try implementing a MetaOptNet-style meta-learner, using `cvxpylayers` or not, and playing around with it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "000002c1dc89469d944f551e7f5b0e40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d87ccbd2fc874ec99956860f93564009",
       "max": 100.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_20d54ef036c84cae907433aa3ae13743",
       "value": 100.0
      }
     },
     "02557b2a4f92402fb05acdea1cc507d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "04776a5b18d04dc0999ae0f8000aa4fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_54044915e8934a5b843373fa1a5b283c",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_593d3a6ba4864eff868b5ef7f9fcc7d2",
       "value": 1.0
      }
     },
     "12093cae81044c5fba7adb2ebc59d86d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "16ffdecde1854416bc06d02ca28a554e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1dba9b057cd74c058902aa065cdc548b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20d54ef036c84cae907433aa3ae13743": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "29074014272847e38b76cb3710d703b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30ce85898e6d420aa6f17df10bd75a16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_02557b2a4f92402fb05acdea1cc507d2",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_fb414a9e917d4f5295374b2c3e1b297c",
       "value": "100%"
      }
     },
     "3764f724ef7f4e3e9fae05fe95982f26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3c7b138377194cf89f40d7da27871aa7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_affa852baeb74f189e3a81a795e86042",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_5fbf68a0c5bd4dd387fe42a05f7fc4a2",
       "value": " 1/1 [00:06&lt;00:00,  6.57s/it, acc=0.481, lam=1.11, loss=0.0143]"
      }
     },
     "413830e56f8d433bacb8d664714095d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54044915e8934a5b843373fa1a5b283c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "593d3a6ba4864eff868b5ef7f9fcc7d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5eeb2d10a1d443ae837a2130bdfa85db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5fbf68a0c5bd4dd387fe42a05f7fc4a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6260b222293b4ad4acb3619f3e5e972a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "652e9eb7aaf543f38b037fa98f8d9fd5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a97957ac95840108b95a0aac0158630": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7e34cf5bed19445d80e554265e69b41c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_98ec2fa27ffb42caaaa8b1771a8e12fc",
        "IPY_MODEL_04776a5b18d04dc0999ae0f8000aa4fa",
        "IPY_MODEL_3c7b138377194cf89f40d7da27871aa7"
       ],
       "layout": "IPY_MODEL_e3bb9d9a47bc4a1daab0c5f2b0493373"
      }
     },
     "98ec2fa27ffb42caaaa8b1771a8e12fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_29074014272847e38b76cb3710d703b6",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_12093cae81044c5fba7adb2ebc59d86d",
       "value": "100%"
      }
     },
     "ac237f6eb2e54981b28d46728fe2e51f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_413830e56f8d433bacb8d664714095d3",
       "max": 100.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6260b222293b4ad4acb3619f3e5e972a",
       "value": 100.0
      }
     },
     "affa852baeb74f189e3a81a795e86042": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b01c7bf17dd74e9b8f1c682e7556f531": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb4aa02e8df64077ac982870c319efdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dcee8e31da5d4812b5b382057b4c3540",
        "IPY_MODEL_000002c1dc89469d944f551e7f5b0e40",
        "IPY_MODEL_c864e1b50b12451bbd43328daf0fe473"
       ],
       "layout": "IPY_MODEL_b01c7bf17dd74e9b8f1c682e7556f531"
      }
     },
     "c864e1b50b12451bbd43328daf0fe473": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_652e9eb7aaf543f38b037fa98f8d9fd5",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_3764f724ef7f4e3e9fae05fe95982f26",
       "value": " 100/100 [00:01&lt;00:00, 81.93it/s]"
      }
     },
     "d87ccbd2fc874ec99956860f93564009": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcee8e31da5d4812b5b382057b4c3540": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1dba9b057cd74c058902aa065cdc548b",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_16ffdecde1854416bc06d02ca28a554e",
       "value": "100%"
      }
     },
     "e0f98f466541408baa4d39ff31eed915": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3bb9d9a47bc4a1daab0c5f2b0493373": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e44714769ebb4b90b108a43b8587a61e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e0f98f466541408baa4d39ff31eed915",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_6a97957ac95840108b95a0aac0158630",
       "value": " 100/100 [00:23&lt;00:00,  3.91it/s, lam=9.549e-05, loss=0.02573, sig=5.474]"
      }
     },
     "ee2e721a960d4172a70c231c60b2b001": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_30ce85898e6d420aa6f17df10bd75a16",
        "IPY_MODEL_ac237f6eb2e54981b28d46728fe2e51f",
        "IPY_MODEL_e44714769ebb4b90b108a43b8587a61e"
       ],
       "layout": "IPY_MODEL_5eeb2d10a1d443ae837a2130bdfa85db"
      }
     },
     "fb414a9e917d4f5295374b2c3e1b297c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}